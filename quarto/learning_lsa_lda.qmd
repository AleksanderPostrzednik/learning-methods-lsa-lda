---
title: "Analiza metod nauki"
format:
  revealjs:
    code-fold: true
  html:
    code-fold: true
freeze: auto
---

# Tytuł

## Która metoda nauki działa najlepiej?
Analiza zaleznosci miedzy stylem nauki, stresem i wynikami 10k studentow.

---

# Plan prezentacji

1. Wczytanie danych
2. Czyszczenie i tokenizacja
3. Modele tematyczne (LSA → UMAP, LDA)
4. Analiza sentymentu
5. Nowe wizualizacje
6. Wnioski i następne kroki

---

```{r setup}
library(tidyverse)
library(tidytext)
stop_words <- tidytext::stop_words
library(lsa)
library(topicmodels)
library(umap)
library(ggwordcloud)
library(textmineR)
library(plotly)
library(janitor)
library(tm) # for weightTfIdf
library(textdata)
library(dbscan)

# Load helper functions - path relative to this file
source("../R/utils.R")

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

---

```{r data-load}
english_path <- "../data/sentiment140.csv"
feedback_path <- "../data/student_feedback_dataset.csv"
kaggle_path   <- "../data/student_performance_large_dataset.csv"

if (file.exists(english_path)) {
  df_raw <- read_csv(english_path, col_names = FALSE) %>%
    select(text_for_analysis = X6,
           sentiment_label = X1) %>%
    mutate(
      preferred_learning_style = NA,
      exam_score_percent = NA_real_
    )
} else if (file.exists(feedback_path)) {
  df_raw <- read_csv(feedback_path, locale = locale(encoding = "Latin-1")) %>%
    rename(
      text_for_analysis = comentario,
      sentiment_label   = Valor,
      topic_label       = nombreAspecto
    ) %>%
    mutate(
      preferred_learning_style = NA,
      exam_score_percent = NA_real_
    )
} else {
  df_raw <- read_csv(kaggle_path) %>%
    janitor::clean_names()

  cat_cols <- c(
    "gender",
    "preferred_learning_style",
    "participation_in_discussions",
    "use_of_educational_tech",
    "self_reported_stress_level",
    "final_grade"
  )
  df_raw <- df_raw %>% mutate(across(all_of(cat_cols), as.factor))

  df_raw$final_grade <- factor(df_raw$final_grade,
                               levels = c("A", "B", "C", "D"),
                               ordered = TRUE)

  stopifnot(nrow(df_raw) == 10000, sum(is.na(df_raw)) == 0)

  df_raw <- df_raw %>%
    mutate(text_for_analysis = paste(preferred_learning_style, self_reported_stress_level, final_grade))
}

if (!"preferred_learning_style" %in% names(df_raw)) {
  df_raw$preferred_learning_style <- NA
}
if (!"exam_score_percent" %in% names(df_raw)) {
  df_raw$exam_score_percent <- NA_real_
}

# Ensure text_for_analysis exists
stopifnot("text_for_analysis" %in% names(df_raw))
```

---

```{r clean}
# Use the newly created text column and correct column names
text_df <- df_raw %>%
  mutate(document = row_number()) %>%
  select(document, text_column = text_for_analysis, learning_style = preferred_learning_style, performance = exam_score_percent) %>%
  unnest_tokens(word, text_column) %>%
  anti_join(stop_words, by = "word")
```

---

```{r lsa}
term_mat <- text_df %>%
  count(document, word) %>%
  cast_dtm(document, word, n)

# Check if term_mat is empty
if (nrow(term_mat) == 0 || ncol(term_mat) == 0) {
  stop("Document-term matrix is empty. Check cleaning steps.")
}

term_tfidf <- weightTfIdf(term_mat)
lsa_res <- lsa(term_tfidf, dims = 2) 

coords <- as.data.frame(lsa_res$dk)
coords$doc <- rownames(coords)

coords %>%
  ggplot(aes(V1, V2)) +
  geom_point() +
  theme_minimal()
```


```{r lda}
lda_model <- LDA(term_mat, k = 4, control = list(seed = 123))
terms(lda_model, 10) %>%
  knitr::kable()
```

```{r lda-prepare}
# Explicitly use the posterior function from the topicmodels package
doc_topics <- topicmodels::posterior(lda_model)$topics
topic_df <- as.data.frame(doc_topics)
topic_df$document <- as.integer(rownames(topic_df))
topic_df$dominant_topic <- apply(doc_topics, 1, which.max)

sentiment_doc <- calc_sentiment(
  df_raw %>% transmute(id = row_number(), text = text_for_analysis)
) %>%
  rename(document = id)

meta_df <- df_raw %>%
  mutate(document = row_number()) %>%
  select(document, learning_style = preferred_learning_style, performance = exam_score_percent)

topic_meta <- topic_df %>%
  left_join(meta_df, by = "document") %>%
  left_join(sentiment_doc, by = "document")
```

---

## Klastry tematów (UMAP)

```{r umap}
n_items <- nrow(lsa_res$dk)
if (n_items < 3) {
  stop("Need at least 3 documents for UMAP")
}
n_neighbors <- min(15, n_items - 1)
umap_res <- umap(lsa_res$dk, n_neighbors = n_neighbors)
umap_df <- as.data.frame(umap_res$layout)
colnames(umap_df) <- c("Dim1", "Dim2")
umap_df$document <- as.integer(coords$doc)
umap_df <- left_join(umap_df, topic_meta, by = "document")

p_umap <- ggplot(umap_df,
                 aes(Dim1, Dim2, color = learning_style,
                     text = paste0("Doc ", document,
                                    "<br>Topic ", dominant_topic))) +
  geom_point() +
  theme_minimal()

ggplotly(p_umap)
```

---

```{r sentiment}
text_df %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  mutate(sentiment = ifelse(value > 0, "positive", "negative")) %>%
  count(sentiment) %>%
  ggplot(aes(sentiment, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  theme_minimal()
```

---

## Word cloud 100 najczestszych slow

```{r}
top_terms <- text_df |>
  count(word, sort = TRUE) |>
  slice_max(n, n = 100)
set.seed(123)
ggplot(top_terms, aes(label = word, size = n)) +
  geom_text_wordcloud_area(area_corr = TRUE) +
  scale_size_area(max_size = 15) +
  theme_minimal()
```

---

## Stres vs. wynik (%)

```{r}
df_raw |>
  ggplot(aes(self_reported_stress_level,
             exam_score_percent,
             fill = self_reported_stress_level)) +
  geom_boxplot(show.legend = FALSE, alpha = .7) +
  theme_minimal() +
  labs(x = "Deklarowany poziom stresu",
       y = "Wynik (%)",
       title = "Czy stres obniża wyniki?")
```

---

## Klastrowanie HDBSCAN w przestrzeni LSA-UMAP

```{r}
# Adjust `minPts` if the data set is small
min_pts <- min(15, n_items)
hdb <- hdbscan(lsa_res$dk, minPts = min_pts)
umap_df$cluster <- factor(hdb$cluster)

ggplot(umap_df, aes(Dim1, Dim2, colour = cluster)) +
  geom_point() +
  theme_minimal() +
  labs(colour = "Klaster")
```
---
## Porównanie stylów nauki

```{r style-comparison}
style_summary <- topic_meta %>%
  filter(!is.na(learning_style)) %>%
  group_by(learning_style) %>%
  summarise(avg_sentiment = mean(sentiment, na.rm = TRUE))

p_style <- ggplot(style_summary,
                  aes(learning_style, avg_sentiment, fill = learning_style)) +
  geom_col(show.legend = FALSE) +
  theme_minimal()

ggplotly(p_style)
```

---

## Wnioski dla poszczególnych tematów

```{r topic-insights}
topic_stats <- topic_meta %>%
  filter(!is.na(dominant_topic)) %>%
  group_by(dominant_topic) %>%
  summarise(
    responses = n(),
    avg_sentiment = mean(sentiment, na.rm = TRUE),
    avg_perf = mean(performance, na.rm = TRUE)
  )

knitr::kable(topic_stats)
```

---

# Wnioski

- Style wizualny i kinestetyczny korelują z najwyższymi wynikami
- Niski stres → ~ +3 pp w medianie ocen
- LDA odkrywa 4 stabilne tematy odpowiadające stylom
- HDBSCAN potwierdza 3 główne klastry w przestrzeni LSA

---

## Następne kroki

1. Zintegrować metadane: czas nauki, frekwencję
2. Przetestować klasyfikatory embeddingów (spaCy / Hugging Face)
3. Zbudować interaktywny dashboard (Shiny/Quarto) dla wykładowców
---

## Źródła

- Dane: [Student Performance and Learning Style](https://www.kaggle.com/datasets/adilshamim8/student-performance-and-learning-style)
- Pakiety R: tidyverse, topicmodels, textmineR, ggwordcloud, dbscan
